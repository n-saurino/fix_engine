feat(benchmarking): Set up Prometheus pipeline and Grafana visualization

Established a benchmarking pipeline by running Prometheus and its Node Exporter as microservices, exposing performance data to Grafana Cloud for visualization. Created a basic dashboard displaying FIX message encoder latency metrics. Decided to run benchmark scripts locally on commits to ensure consistency, avoiding potential variability introduced by GitHub Actions server load. Additionally, improved logging structure by separating CSV files for internal analysis and Prometheus logs for external visualization. Organized project scripts into a dedicated `scripts` folder. Implemented a cron job to rotate benchmark logs every minute for efficient log management.

Changes:
- Deployed Prometheus and Node Exporter as microservices for performance monitoring.
- Integrated Prometheus with Grafana Cloud to visualize FIX message encoder latency metrics.
- Created an initial Grafana dashboard for real-time performance tracking.
- Chose to run benchmark scripts locally on commits to maintain consistency.
- Added separate logs for CSV (internal analysis) and Prometheus (external visualization).
- Organized project-related scripts into a dedicated `scripts/` directory.
- Implemented a cron job to rotate benchmark logs every minute.
- Exposed Grafana dashboard publicly and updated readme to include the link

Next steps:
- Expand Grafana dashboard with additional performance metrics and visualizations.
- Optimize Prometheus data collection for lower-latency reporting.
- Investigate additional benchmark optimizations for FIX message encoding.

Authored and reviewed by: Nigel Saurino
